{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0    ...          17.33           184.60      2019.0           0.16220   \n",
       "1    ...          23.41           158.80      1956.0           0.12380   \n",
       "2    ...          25.53           152.50      1709.0           0.14440   \n",
       "3    ...          26.50            98.87       567.7           0.20980   \n",
       "4    ...          16.67           152.20      1575.0           0.13740   \n",
       "..   ...            ...              ...         ...               ...   \n",
       "564  ...          26.40           166.10      2027.0           0.14100   \n",
       "565  ...          38.25           155.00      1731.0           0.11660   \n",
       "566  ...          34.12           126.70      1124.0           0.11390   \n",
       "567  ...          39.42           184.60      1821.0           0.16500   \n",
       "568  ...          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.66560           0.7119                0.2654          0.4601   \n",
       "1              0.18660           0.2416                0.1860          0.2750   \n",
       "2              0.42450           0.4504                0.2430          0.3613   \n",
       "3              0.86630           0.6869                0.2575          0.6638   \n",
       "4              0.20500           0.4000                0.1625          0.2364   \n",
       "..                 ...              ...                   ...             ...   \n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "0                    0.11890          NaN  \n",
       "1                    0.08902          NaN  \n",
       "2                    0.08758          NaN  \n",
       "3                    0.17300          NaN  \n",
       "4                    0.07678          NaN  \n",
       "..                       ...          ...  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[569 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign 357\n",
      "Malignant 212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YASHRAJ\\anaconda3\\envs\\gpuenv\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(dataset['diagnosis'],label='Count')\n",
    "B,M = dataset['diagnosis'].value_counts()\n",
    "print('Benign',B)\n",
    "print('Malignant',M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop('Unnamed: 32',axis=1,inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.iloc[:,2:]\n",
    "y = dataset.iloc[:, 1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    M\n",
       "1    M\n",
       "2    M\n",
       "3    M\n",
       "4    M\n",
       "Name: diagnosis, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.65079907 -0.43057322 -0.68024847 ... -0.36433881  0.32349851\n",
      "  -0.7578486 ]\n",
      " [-0.82835341  0.15226547 -0.82773762 ... -1.45036679  0.62563098\n",
      "  -1.03071387]\n",
      " [ 1.68277234  2.18977235  1.60009756 ...  0.72504581 -0.51329768\n",
      "  -0.96601386]\n",
      " ...\n",
      " [-1.33114223 -0.22172269 -1.3242844  ... -0.98806491 -0.69995543\n",
      "  -0.12266325]\n",
      " [-1.25110186 -0.24600763 -1.28700242 ... -1.75887319 -1.56206114\n",
      "  -1.00989735]\n",
      " [-0.74662205  1.14066273 -0.72203706 ... -0.2860679  -1.24094654\n",
      "   0.2126516 ]]\n",
      "[[-0.1839902   0.22170989 -0.11761404 ...  1.40089716  1.16977773\n",
      "   1.37108056]\n",
      " [-0.23927557  1.20953909 -0.30776593 ... -0.79588429 -0.81775175\n",
      "  -0.91991041]\n",
      " [-0.00358531 -0.79326895 -0.07782455 ... -0.46102846 -1.35426278\n",
      "  -0.9614486 ]\n",
      " ...\n",
      " [-0.49242436 -1.50124802 -0.52388569 ... -0.0848268   0.34236625\n",
      "  -0.49174753]\n",
      " [-0.14616337 -1.77900972 -0.14818913 ... -0.58355147 -0.35440132\n",
      "  -0.70529643]\n",
      " [ 1.61714893 -0.27324893  1.6440133  ...  1.69773906  1.27080903\n",
      "   0.37682669]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(input_dim = 30,units = 16,kernel_initializer = 'uniform',activation='relu'))\n",
    "# input_dim = Total number of columns excluding the target variable, and the columns removed .\n",
    "classifier.add(Dense(units = 16,kernel_initializer = 'uniform',activation='relu'))\n",
    "classifier.add(Dense(units = 1,kernel_initializer = 'uniform',activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5047\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.6549\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6894 - accuracy: 0.6901\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.7746\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.8568\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6756 - accuracy: 0.8991\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6667 - accuracy: 0.9202\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.9296\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6383 - accuracy: 0.9390\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6179 - accuracy: 0.9437\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.9437\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.9507\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5268 - accuracy: 0.9507\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.9507\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.9531\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.9577\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3610 - accuracy: 0.9601\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3205 - accuracy: 0.9624\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2840 - accuracy: 0.9648\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.9671\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2229 - accuracy: 0.9695\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1984 - accuracy: 0.9718\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.9742\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1612 - accuracy: 0.9742\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1471 - accuracy: 0.9789\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1360 - accuracy: 0.9789\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 0.9789\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1185 - accuracy: 0.9765\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1116 - accuracy: 0.9765\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1062 - accuracy: 0.9765\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1011 - accuracy: 0.9765\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0968 - accuracy: 0.9765\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0931 - accuracy: 0.9765\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0899 - accuracy: 0.9765\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0870 - accuracy: 0.9765\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0845 - accuracy: 0.9812\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0822 - accuracy: 0.9812\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0801 - accuracy: 0.9812\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0785 - accuracy: 0.9836\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0766 - accuracy: 0.9836\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.98 - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9836\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0739 - accuracy: 0.9836\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0728 - accuracy: 0.9836\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9836\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.9859\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.9859\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.98 - 0s 3ms/step - loss: 0.0689 - accuracy: 0.9859\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.9859\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.98 - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9859\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0666 - accuracy: 0.9859\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9859\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.9859\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9859\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9859\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0634 - accuracy: 0.9859\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9859\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9859\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.9859\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9859\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9859\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9859\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9859\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9859\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.9859\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9859\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9859\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9859\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0564 - accuracy: 0.9883\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9883\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9883\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0552 - accuracy: 0.9883\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9883\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9883\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9883\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0537 - accuracy: 0.9883\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9883\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0530 - accuracy: 0.9883\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9883\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9883\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 0.9883\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9883\n",
      "Epoch 82/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9883\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9883\n",
      "Epoch 84/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 0.9883\n",
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9883\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9883\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9883\n",
      "Epoch 88/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0492 - accuracy: 0.9883\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9883\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9883\n",
      "Epoch 91/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9883\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9883\n",
      "Epoch 93/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9883\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.9883\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9883\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9883\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9883\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9906\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9906\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0456 - accuracy: 0.9906\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9906\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9906\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9906\n",
      "Epoch 104/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9906\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9906\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9906\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9906\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9906\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9906\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9906\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9906\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9906\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0423 - accuracy: 0.9906\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9906\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9906\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9906\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0414 - accuracy: 0.9906\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9906\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.9906\n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9906\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9906\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9906\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9906\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9906\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9906\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.9906\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9906\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9906\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9906\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0389 - accuracy: 0.9906\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 0.9906\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.9906\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9906\n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9906\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9906\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9906\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9906\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0372 - accuracy: 0.9906\n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9906\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9906\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0368 - accuracy: 0.9906\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9906\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9906\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 0.9906\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.9906\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9906\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9906\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9906\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9906\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29c310c0550>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train,epochs=150,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[86,  4],\n",
       "       [ 4, 49]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAASzklEQVR4nO3de5BcZZnH8e+TQK7cEiFxCO6CEkB0lVVELgJCEAHFxNVYYOEObDRLiSCKq0FRCsticUtxdS9Vm0JkLBAMNxPdAsyOIqsCEiByS6woi+EyZOSOyG2mn/1jDjiGMKeH9JnunHw/1Fun+3T3O88f+OP1Pe95T2QmkqTqjGt3AZJUdwatJFXMoJWkihm0klQxg1aSKrZF1X/g+YfudlmDXmLyjge2uwR1oIHn7o+N7WM0mbPl9q/d6L/XDEe0klSxyke0kjSmGoPtruAlDFpJ9TI40O4KXsKglVQrmY12l/ASBq2kemkYtJJULUe0klQxL4ZJUsUc0UpStdJVB5JUMS+GSVLFnDqQpIp14MUw9zqQVC/ZaL6ViIhPRcSdEXFHRFwcEZMiYnpELI+INcVxWlk/Bq2kehkcaL6NICJmAacAe2fmG4HxwDHAIqA3M2cDvcX7ERm0kuql0Wi+ldsCmBwRWwBTgAeAuUBP8XkPMK+sE4NWUq1kDjbdImJhRKwY1hb+uZ+8H/gasBboAx7PzB8DMzOzr/hOHzCjrCYvhkmql1GsOsjMxcDiDX1WzL3OBXYBHgMujYjjXklJBq2kemndOtrDgP/LzD8ARMQVwP7Auojoysy+iOgC+ss6cupAUr20btXBWmDfiJgSEQHMAVYBy4Du4jvdwNKyjhzRSqqXwedb0k1m3hgRlwG3AAPArQxNM2wFLImIBQyF8fyyvgxaSfXSwltwM/NM4Mz1Tj/L0Oi2aQatpHrxFlxJqpibykhSxQxaSapWtuhiWCsZtJLqxTlaSaqYUweSVDFHtJJUMUe0klQxR7SSVLEBn4IrSdVyRCtJFXOOVpIq5ohWkirmiFaSKuaIVpIq5qoDSapYZrsreAmDVlK9dOAcrQ9nlFQvjUbzbQQRsXtErBzWnoiIUyNiekQsj4g1xXFaWUkGraR6adFTcDPzN5m5V2buBbwV+BNwJbAI6M3M2UBv8X5EBq2kehkcbL41bw7wu8z8PTAX6CnO9wDzyn5s0Eqql1FMHUTEwohYMawtfJlejwEuLl7PzMw+gOI4o6wkL4ZJqpdRXAzLzMXA4pG+ExETgPcBp7/SkgxaSfXS+hsWjgRuycx1xft1EdGVmX0R0QX0l3Xg1IGkWslGNt2adCx/njYAWAZ0F6+7gaVlHTiilVQvLVxHGxFTgHcB/zjs9DnAkohYAKwF5pf1Y9BKqpfRrSYYUWb+CXjVeuceZmgVQtMMWkn10oF3hhm0kurFoN18fPeSK7n8h1cTEcx+3c585fOfZuLECVx06VIuvvyHjB8/noP234fTTlrQ7lLVRuPGjePGG67igfsfZO77u8t/oHJuKrN5WPeHh7josqUsvei/mDRxIqd98Wyu+p+fseOrZ/DTn9/AFd/9TyZMmMDDjz7W7lLVZqec/FFWr17DNltv3e5S6qMDR7Sly7siYo+I+FxEfCsivlm8fv1YFLcpGxgc5Nlnn2NgYJCnn3mWHbafzvd/8N8sOO5DTJgwAYBXTduuvUWqrWbN6uKoI+dw/vkXl39ZzWtk822MjBi0EfE54BIggF8BNxWvL46I0o0UNlczd9ie44/9AIf93d9zyNwPs/XUKRzw9rdyz9r7ufnXd3Dsx07l+JP+idtX/abdpaqNzv36WSw6/Ss0OnAEtkmrZq+DjVI2ol0AvC0zz8nMC4t2DrBP8dkGDb9/+Lzvbn7/tX78iSf56f/ewDWXfoefLL2Ip595lh9e8xMGBwd54sk/8r3F3+C0kz7KZ774z2QHziepeu856jD6+x/illtvb3cptZONRtNtrJTN0TaAHYHfr3e+q/hsg4bfP/z8Q3dvdklyw4qVzNpxJtOLqYE5B+/PytvvYuaM7Tns4AOICP5mz92JCB597PEXv6fNx/77783R7z2cI484lEmTJrLNNlvTc8G36D7+lHaXtukbwymBZpUF7alAb0SsAe4tzv0VsCvwiQrr2qR1zdyB2+5YzdPPPMOkiRO5ccVK3rDHbHZ73S786uaV7POWN3HP2vt4fmCAadtt2+5y1QZfOOMcvnDGOQAcfNB+fPpTJxqyrbKpPZwxM6+OiN0YmiqYxdD87H3ATZk5dhMcm5g3vWEP3nXIO/jQCSczfvx49tjtdcyfeyQRwRlnf4N5x53IlltuwdlnnEZEtLtcqV46cEQbVc8Rbo5TByo3eccD212COtDAc/dv9MjjqS8d03TmTP3yJWMy0nEdraR62dSmDiRpk9OBUwcGraRaGctlW80yaCXViyNaSaqYQStJFRvDW2ub5TPDJNVKK58ZFhHbRcRlEbE6IlZFxH4RMT0ilkfEmuI4rawfg1ZSvbR2965vAldn5h7Am4FVwCKgNzNnA73F+xEZtJLqpdFovo0gIrYBDgK+DZCZz2XmY8BcoKf4Wg8wr6wkg1ZSvYxiRDt8p8GiLRzW02uBPwDfiYhbI+K8iJgKzMzMPoDiOKOsJC+GSaqXUaw6GL7T4AZsAbwFODkzb4yIb9LENMGGOKKVVCs52Gi6lbgPuC8zbyzeX8ZQ8K6LiC6A4thf1pFBK6leWnQxLDMfBO6NiN2LU3OAu4BlwAtP0uwGlpaV5NSBpFppZtnWKJwMXBQRE4C7gRMYGqAuiYgFwFpgflknBq2kemlh0GbmSmDvDXw0ZzT9GLSS6qXz9pQxaCXVSw50XtIatJLqpfNy1qCVVC8tvhjWEgatpHpxRCtJ1XJEK0lVc0QrSdXKgXZX8FIGraRa6cCnjRu0kmrGoJWkajmilaSKGbSSVLEcjHaX8BIGraRacUQrSRXLhiNaSaqUI1pJqlimI1pJqpQjWkmqWKOFqw4i4h7gSWAQGMjMvSNiOvB9YGfgHuBDmfnoSP34FFxJtZKNaLo16ZDM3CszX3h22CKgNzNnA73F+xEZtJJqpYKgXd9coKd43QPMK/uBQSupVjKbbxGxMCJWDGsL1+8O+HFE3Dzss5mZ2Tf0t7IPmFFWk3O0kmplNCPVzFwMLB7hKwdk5gMRMQNYHhGrX0lNjmgl1UpmNN3K+8oHimM/cCWwD7AuIroAimN/WT8GraRaGRyMpttIImJqRGz9wmvgcOAOYBnQXXytG1haVpNTB5JqpYU3LMwErowIGMrK72Xm1RFxE7AkIhYAa4H5ZR0ZtJJqpVV7HWTm3cCbN3D+YWDOaPoyaCXVSnbeQ3ANWkn14u5dklSxwUbnXeM3aCXVilMHklSxhtskSlK13I9Wkiq2WU4dTN7xwKr/hDZBq3d9Y7tLUE05dSBJFXPVgSRVrANnDgxaSfXi1IEkVcxVB5JUsQ58CK5BK6leEke0klSpAacOJKlajmglqWKdOEfbeSt7JWkjJNF0a0ZEjI+IWyPiR8X76RGxPCLWFMdpZX0YtJJqpTGK1qRPAquGvV8E9GbmbKC3eD8ig1ZSrQwSTbcyEbET8B7gvGGn5wI9xeseYF5ZPwatpFppRPMtIhZGxIphbeF63f0r8Fn+cgA8MzP7AIrjjLKavBgmqVYao1h1kJmLgcUb+iwi3gv0Z+bNEfHOjanJoJVUKy3cVOYA4H0RcRQwCdgmIi4E1kVEV2b2RUQX0F/WkVMHkmqlVRfDMvP0zNwpM3cGjgF+kpnHAcuA7uJr3cDSspoc0UqqlUZUfsPCOcCSiFgArAXml/3AoJVUK4MV9JmZ1wLXFq8fBuaM5vcGraRaaXTeHbgGraR6Gc2qg7Fi0EqqFR9lI0kVc+pAkirWibt3GbSSamXQEa0kVcsRrSRVzKCVpIp14CPDDFpJ9eKIVpIqVsUtuBvLoJVUK66jlaSKOXUgSRUzaCWpYu51IEkVc45WkirmqgNJqlijAycPfDijpFpp1cMZI2JSRPwqIn4dEXdGxFnF+ekRsTwi1hTHaWU1GbSSaiVH0Uo8CxyamW8G9gKOiIh9gUVAb2bOBnqL9yMyaCXVSgsfN56Z+cfi7ZZFS2Au0FOc7wHmldVk0EqqlYHIpltELIyIFcPawuF9RcT4iFgJ9APLM/NGYGZm9gEUxxllNXkxTFKtjOZSWGYuBhaP8PkgsFdEbAdcGRFvfCU1OaKVVCutmjoYLjMfA64FjgDWRUQXQHHsL/u9QSupVhpk020kEbFDMZIlIiYDhwGrgWVAd/G1bmBpWU1OHUiqlRauou0CeiJiPEOD0iWZ+aOIuB5YEhELgLXA/LKODFpJtdKqTWUy8zbgbzdw/mFgzmj6Mmgl1cpgB94ZZtBKqhW3SZSkiqUjWkmqliPazdi4ceO48YareOD+B5n7/u7yH6i+xo3jNZf+GwPrHqbv419iwu6vZcaZJxNTJjNw/zoe/OxXyaf+1O4qN1nu3rUZO+Xkj7J69Zp2l6EOsN1H5vHc7+598f2ML5/KQ+eez73zTuSPvb9g2j98sI3VbfpauKlMyxi0Y2DWrC6OOnIO559/cbtLUZuNn7k9Uw7ehycuv+rFcxN22YlnVtwOwNO/vJWtDn9Hu8qrhQGy6TZWDNoxcO7Xz2LR6V+h0ejE2SONpR0WncjDXzsPGn/+H/mza37P1EP3A2Crdx/IFq/eoV3l1UKO4p+x8oqDNiJOGOGzF3fEaTSeeqV/ohbec9Rh9Pc/xC233t7uUtRmUw5+O4OPPMazd/32L873n3Eu2x57NDtd+u/E1Mnk8wNtqrAeqtjrYGNtzMWws4DvbOiD4TvibDFhVufNTI+h/fffm6PfezhHHnEokyZNZJtttqbngm/Rffwp7S5NY2zyW/Zk6iH7MuWgtxETJzBu6hRmfvWzrPvcv/DAxz4PwJZ/PYupB729zZVu2jpxeVdkvnxREXHby30E7JaZE8v+wOYetMMdfNB+fPpTJ7rqAFi96yvaba42Jr/tTWx3wgfp+/iXGD99WwYfeRwimHH2Z3j6pl/z5BU/bneJbbHrXdds9DNsu3f+QNOZ03PP5WPyzNyyEe1M4N3Ao+udD+CXlVQkbWa2OuoQtv3w0QA8tfwXm23ItsrgCIPHdikL2h8BW2XmyvU/iIhrqyiozn523fX87Lrr212GOsDTN93G0zcN/R/Gxy/8AY9f+IP2FlQjnbiOdsSgzcwFI3z24daXI0kbpxPnaL0zTFKtdOIiSoNWUq1sclMHkrSp6cSpA+8Mk1Qrg5lNt5FExGsi4qcRsSoi7oyITxbnp0fE8ohYUxynldVk0EqqlVY9nBEYAE7LzNcD+wInRcSewCKgNzNnA73F+xEZtJJqpVW34GZmX2beUrx+ElgFzALmAj3F13qAeWU1GbSSamU0m8oM35elaAs31GdE7MzQgxpvBGZmZh8MhTEwo6wmL4ZJqpXRrDoYvi/Ly4mIrYDLgVMz84mI0d+1a9BKqpWR9m8ZrYjYkqGQvSgzryhOr4uIrszsi4guoL+sH6cOJNXKINl0G0kMDV2/DazKzHOHfbQMeGFnqG5gaVlNjmgl1UoLb1g4APgIcHtErCzOfR44B1gSEQuAtcD8so4MWkm10qqpg8z8OUM7FW7InNH0ZdBKqhVvwZWkinXiLbgGraRa2RQ3/pakTYpTB5JUMYNWkirWyhsWWsWglVQrjmglqWKuOpCkig1m5z01zKCVVCvO0UpSxZyjlaSKOUcrSRVrOHUgSdVyRCtJFXPVgSRVzKkDSaqYUweSVLFOHNH6cEZJtZKj+KdMRJwfEf0Rccewc9MjYnlErCmO08r6MWgl1cpgDjbdmnABcMR65xYBvZk5G+gt3o/IoJVUK5nZdGuir+uAR9Y7PRfoKV73APPK+jFoJdVKg2y6RcTCiFgxrC1s4k/MzMw+gOI4o+wHXgyTVCuj2VQmMxcDi6urZohBK6lWxmDVwbqI6MrMvojoAvrLfuDUgaRaaeWqg5exDOguXncDS8t+4IhWUq208hbciLgYeCewfUTcB5wJnAMsiYgFwFpgflk/Bq2kWmnlxt+ZeezLfDRnNP0YtJJqpRPvDDNoJdWKj7KRpIr5KBtJqpgjWkmqmBt/S1LFvBgmSRVz6kCSKuYTFiSpYo5oJalinThHG52Y/nUVEQuLbdmkF/nvRf25e9fYamZTYW1+/Pei5gxaSaqYQStJFTNox5bzcNoQ/72oOS+GSVLFHNFKUsUMWkmqmEE7RiLiiIj4TUT8NiIWtbsetV9EnB8R/RFxR7trUbUM2jEQEeOB/wCOBPYEjo2IPdtblTrABcAR7S5C1TNox8Y+wG8z8+7MfA64BJjb5prUZpl5HfBIu+tQ9QzasTELuHfY+/uKc5I2Awbt2IgNnHNdnbSZMGjHxn3Aa4a93wl4oE21SBpjBu3YuAmYHRG7RMQE4BhgWZtrkjRGDNoxkJkDwCeAa4BVwJLMvLO9VandIuJi4Hpg94i4LyIWtLsmVcNbcCWpYo5oJaliBq0kVcyglaSKGbSSVDGDVpIqZtBKUsUMWkmq2P8DqXJyqHmTWF8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('confusion_matrix.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
